{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('full_data.csv')\n",
    "col_list = data.columns.tolist()\n",
    "features = col_list.copy()\n",
    "features.remove('y')\n",
    "num_cols = [col for col in features if data[col].dtype=='int64']\n",
    "data_le = pd.read_csv('encoded_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mm = data_le.copy()\n",
    "for num_col in num_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    data_mm[num_col] = scaler.fit_transform(data_le[num_col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVRfc(df, n_splits=5,  rando_state=2021, features=features, if_print=True, \n",
    "                  *args, **kwargs):\n",
    "    # Prepare KStratifiedKFOLD\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rando_state)\n",
    "    \n",
    "    # Make copy of data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Prepare empty lists\n",
    "    train_results = []\n",
    "    test_results = []\n",
    "    preds = []\n",
    "    \n",
    "    # Prepare int to count fold s\n",
    "    fold_number = 1\n",
    "       \n",
    "    for train, test in kf.split(data.index.values, data['y']):\n",
    "        # Prepare KNN model \n",
    "        model = RandomForestClassifier(*args, **kwargs)\n",
    "        model.fit(data.loc[train, features], data.loc[train, 'y'])\n",
    "        \n",
    "        # Make predictions\n",
    "        train_preds = model.predict(data.loc[train, features])\n",
    "        test_preds = model.predict(data.loc[test, features])\n",
    "        preds.append(test_preds)\n",
    "        \n",
    "        # Prepare ROC_AUC score\n",
    "        train_roc = metrics.roc_auc_score(data.loc[train, 'y'], train_preds)\n",
    "        test_roc = metrics.roc_auc_score(data.loc[test, 'y'], test_preds)\n",
    "        \n",
    "        # Add ROC_AUC to lis\n",
    "        train_results.append(train_roc)\n",
    "        test_results.append(test_roc)\n",
    "        \n",
    "        if if_print:\n",
    "            print(f'FOLD NUMBER: {fold_number}')\n",
    "            print(f'ROC_AUC ON TRAIN SCORE {train_roc}')\n",
    "            print(f'ROC_AUC ON TEST SCORE {test_roc}')\n",
    "                  \n",
    "        fold_number += 1 \n",
    "        \n",
    "    return train_results, test_results, preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD NUMBER: 1\n",
      "ROC_AUC ON TRAIN SCORE 0.9998227336088584\n",
      "ROC_AUC ON TEST SCORE 0.7750840956071594\n",
      "FOLD NUMBER: 2\n",
      "ROC_AUC ON TRAIN SCORE 0.9997692519530665\n",
      "ROC_AUC ON TEST SCORE 0.7709149438593255\n",
      "FOLD NUMBER: 3\n",
      "ROC_AUC ON TRAIN SCORE 0.9998594052808116\n",
      "ROC_AUC ON TEST SCORE 0.7772499723169894\n",
      "FOLD NUMBER: 4\n",
      "ROC_AUC ON TRAIN SCORE 0.999876226704577\n",
      "ROC_AUC ON TEST SCORE 0.7706953609493175\n",
      "FOLD NUMBER: 5\n",
      "ROC_AUC ON TRAIN SCORE 0.999822750768748\n",
      "ROC_AUC ON TEST SCORE 0.7806489795981826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.9998227336088584,\n",
       "  0.9997692519530665,\n",
       "  0.9998594052808116,\n",
       "  0.999876226704577,\n",
       "  0.999822750768748],\n",
       " [0.7750840956071594,\n",
       "  0.7709149438593255,\n",
       "  0.7772499723169894,\n",
       "  0.7706953609493175,\n",
       "  0.7806489795981826],\n",
       " [array([0, 0, 1, ..., 0, 0, 1]),\n",
       "  array([0, 1, 0, ..., 0, 0, 1]),\n",
       "  array([0, 1, 0, ..., 0, 0, 0]),\n",
       "  array([0, 1, 0, ..., 0, 1, 0]),\n",
       "  array([0, 0, 0, ..., 1, 0, 0])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVRfc(df=data_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rfc_h_tuning(data):\n",
    "    test_list = []\n",
    "    for i in range(60):\n",
    "        param_dict = {\n",
    "            'n_estimators': random.randrange(50, 200, 10),\n",
    "            'max_depth': random.randrange(5, 25, 2),\n",
    "            'max_features': random.randrange(2, 15, 1),\n",
    "            'min_samples_split': random.randrange(2, 10, 1)\n",
    "        }\n",
    "        param_dict['min_samples_leaf'] = random.randrange(1, param_dict['min_samples_split'])\n",
    "\n",
    "        train_results, test_results, preds = CVRfc(df=data, if_print=False, **param_dict)\n",
    "        if i % 5 == 0:\n",
    "            print(param_dict.items(), np.mean(test_results))\n",
    "        test_list.append([param_dict.items(), np.mean(test_results)])\n",
    "        \n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('n_estimators', 130), ('max_depth', 5), ('max_features', 5), ('min_samples_split', 6), ('min_samples_leaf', 4)]) 0.7410283059305712\n",
      "dict_items([('n_estimators', 60), ('max_depth', 15), ('max_features', 10), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.7795067647020287\n",
      "dict_items([('n_estimators', 80), ('max_depth', 17), ('max_features', 3), ('min_samples_split', 6), ('min_samples_leaf', 5)]) 0.7744738859329147\n",
      "dict_items([('n_estimators', 120), ('max_depth', 13), ('max_features', 11), ('min_samples_split', 8), ('min_samples_leaf', 6)]) 0.7748085581622572\n",
      "dict_items([('n_estimators', 160), ('max_depth', 5), ('max_features', 14), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7456613160098896\n",
      "dict_items([('n_estimators', 110), ('max_depth', 11), ('max_features', 7), ('min_samples_split', 6), ('min_samples_leaf', 2)]) 0.7690065149329117\n",
      "dict_items([('n_estimators', 100), ('max_depth', 21), ('max_features', 11), ('min_samples_split', 5), ('min_samples_leaf', 4)]) 0.7782810197740208\n",
      "dict_items([('n_estimators', 150), ('max_depth', 13), ('max_features', 11), ('min_samples_split', 7), ('min_samples_leaf', 6)]) 0.7760483568188465\n",
      "dict_items([('n_estimators', 50), ('max_depth', 5), ('max_features', 8), ('min_samples_split', 8), ('min_samples_leaf', 7)]) 0.7428817286529436\n",
      "dict_items([('n_estimators', 140), ('max_depth', 5), ('max_features', 9), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7428048605293233\n",
      "dict_items([('n_estimators', 110), ('max_depth', 9), ('max_features', 5), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7503029863135228\n",
      "dict_items([('n_estimators', 70), ('max_depth', 9), ('max_features', 4), ('min_samples_split', 7), ('min_samples_leaf', 1)]) 0.7490355490452993\n",
      "dict_items([('n_estimators', 100), ('max_depth', 15), ('max_features', 9), ('min_samples_split', 9), ('min_samples_leaf', 8)]) 0.7769551805815801\n",
      "dict_items([('n_estimators', 130), ('max_depth', 19), ('max_features', 11), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7803991618778602\n",
      "dict_items([('n_estimators', 60), ('max_depth', 13), ('max_features', 11), ('min_samples_split', 9), ('min_samples_leaf', 1)]) 0.7769896248421251\n",
      "dict_items([('n_estimators', 70), ('max_depth', 7), ('max_features', 5), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.7462946136479959\n",
      "dict_items([('n_estimators', 190), ('max_depth', 9), ('max_features', 10), ('min_samples_split', 6), ('min_samples_leaf', 1)]) 0.754716448793653\n",
      "dict_items([('n_estimators', 170), ('max_depth', 21), ('max_features', 7), ('min_samples_split', 6), ('min_samples_leaf', 3)]) 0.7790256518369232\n",
      "dict_items([('n_estimators', 90), ('max_depth', 11), ('max_features', 10), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7726427893724603\n",
      "dict_items([('n_estimators', 110), ('max_depth', 15), ('max_features', 13), ('min_samples_split', 4), ('min_samples_leaf', 1)]) 0.779399162495707\n",
      "dict_items([('n_estimators', 110), ('max_depth', 13), ('max_features', 6), ('min_samples_split', 9), ('min_samples_leaf', 4)]) 0.7738306728776051\n",
      "dict_items([('n_estimators', 60), ('max_depth', 7), ('max_features', 9), ('min_samples_split', 5), ('min_samples_leaf', 4)]) 0.7482269937285964\n",
      "dict_items([('n_estimators', 90), ('max_depth', 13), ('max_features', 7), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7750778473579052\n",
      "dict_items([('n_estimators', 160), ('max_depth', 19), ('max_features', 7), ('min_samples_split', 4), ('min_samples_leaf', 1)]) 0.7800538462624413\n",
      "dict_items([('n_estimators', 50), ('max_depth', 23), ('max_features', 4), ('min_samples_split', 6), ('min_samples_leaf', 5)]) 0.7776943169907942\n",
      "dict_items([('n_estimators', 90), ('max_depth', 15), ('max_features', 6), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7776909362476079\n",
      "dict_items([('n_estimators', 80), ('max_depth', 15), ('max_features', 14), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7792689341074105\n",
      "dict_items([('n_estimators', 190), ('max_depth', 5), ('max_features', 13), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7455257091534259\n",
      "dict_items([('n_estimators', 160), ('max_depth', 9), ('max_features', 9), ('min_samples_split', 5), ('min_samples_leaf', 4)]) 0.7544454730057557\n",
      "dict_items([('n_estimators', 120), ('max_depth', 11), ('max_features', 3), ('min_samples_split', 8), ('min_samples_leaf', 7)]) 0.7542555617431825\n",
      "dict_items([('n_estimators', 60), ('max_depth', 9), ('max_features', 6), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7519092522396733\n",
      "dict_items([('n_estimators', 140), ('max_depth', 11), ('max_features', 14), ('min_samples_split', 6), ('min_samples_leaf', 1)]) 0.7736131888371305\n",
      "dict_items([('n_estimators', 190), ('max_depth', 23), ('max_features', 3), ('min_samples_split', 6), ('min_samples_leaf', 3)]) 0.7787200744451216\n",
      "dict_items([('n_estimators', 180), ('max_depth', 11), ('max_features', 11), ('min_samples_split', 7), ('min_samples_leaf', 1)]) 0.7730240784973136\n",
      "dict_items([('n_estimators', 150), ('max_depth', 11), ('max_features', 6), ('min_samples_split', 6), ('min_samples_leaf', 5)]) 0.7665126523808907\n",
      "dict_items([('n_estimators', 160), ('max_depth', 15), ('max_features', 8), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7790693747672646\n",
      "dict_items([('n_estimators', 130), ('max_depth', 17), ('max_features', 2), ('min_samples_split', 7), ('min_samples_leaf', 3)]) 0.7692287993386284\n",
      "dict_items([('n_estimators', 130), ('max_depth', 23), ('max_features', 9), ('min_samples_split', 7), ('min_samples_leaf', 6)]) 0.7788972638302483\n",
      "dict_items([('n_estimators', 50), ('max_depth', 21), ('max_features', 11), ('min_samples_split', 9), ('min_samples_leaf', 8)]) 0.7768499528819849\n",
      "dict_items([('n_estimators', 70), ('max_depth', 7), ('max_features', 8), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7481954621045838\n",
      "dict_items([('n_estimators', 110), ('max_depth', 15), ('max_features', 2), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.7630845208475563\n",
      "dict_items([('n_estimators', 130), ('max_depth', 19), ('max_features', 6), ('min_samples_split', 8), ('min_samples_leaf', 6)]) 0.7785539897329119\n",
      "dict_items([('n_estimators', 160), ('max_depth', 13), ('max_features', 2), ('min_samples_split', 4), ('min_samples_leaf', 2)]) 0.7590592995565936\n",
      "dict_items([('n_estimators', 150), ('max_depth', 17), ('max_features', 11), ('min_samples_split', 6), ('min_samples_leaf', 3)]) 0.780686203682539\n",
      "dict_items([('n_estimators', 180), ('max_depth', 19), ('max_features', 11), ('min_samples_split', 5), ('min_samples_leaf', 4)]) 0.7803006555067993\n",
      "dict_items([('n_estimators', 160), ('max_depth', 15), ('max_features', 10), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7790126154574766\n",
      "dict_items([('n_estimators', 190), ('max_depth', 5), ('max_features', 3), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7279172467148639\n",
      "dict_items([('n_estimators', 190), ('max_depth', 21), ('max_features', 5), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7818446298656224\n",
      "dict_items([('n_estimators', 80), ('max_depth', 5), ('max_features', 6), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.7423260014314358\n",
      "dict_items([('n_estimators', 120), ('max_depth', 15), ('max_features', 7), ('min_samples_split', 5), ('min_samples_leaf', 2)]) 0.7770078640444541\n",
      "dict_items([('n_estimators', 60), ('max_depth', 23), ('max_features', 11), ('min_samples_split', 5), ('min_samples_leaf', 3)]) 0.7796441058672674\n",
      "dict_items([('n_estimators', 170), ('max_depth', 9), ('max_features', 6), ('min_samples_split', 6), ('min_samples_leaf', 2)]) 0.7518616436709225\n",
      "dict_items([('n_estimators', 110), ('max_depth', 19), ('max_features', 6), ('min_samples_split', 9), ('min_samples_leaf', 7)]) 0.7786345678496567\n",
      "dict_items([('n_estimators', 70), ('max_depth', 5), ('max_features', 14), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.7456588975253431\n",
      "dict_items([('n_estimators', 100), ('max_depth', 5), ('max_features', 4), ('min_samples_split', 6), ('min_samples_leaf', 3)]) 0.7357186996776341\n",
      "dict_items([('n_estimators', 60), ('max_depth', 9), ('max_features', 12), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7594762442383365\n",
      "dict_items([('n_estimators', 90), ('max_depth', 19), ('max_features', 10), ('min_samples_split', 7), ('min_samples_leaf', 6)]) 0.7790684417385065\n",
      "dict_items([('n_estimators', 70), ('max_depth', 15), ('max_features', 12), ('min_samples_split', 2), ('min_samples_leaf', 1)]) 0.7802803819756384\n",
      "dict_items([('n_estimators', 60), ('max_depth', 19), ('max_features', 7), ('min_samples_split', 7), ('min_samples_leaf', 2)]) 0.7799959780938919\n",
      "dict_items([('n_estimators', 130), ('max_depth', 9), ('max_features', 6), ('min_samples_split', 4), ('min_samples_leaf', 3)]) 0.752076592041329\n"
     ]
    }
   ],
   "source": [
    "tuned_list = Rfc_h_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('n_estimators', 50), ('max_depth', 9), ('max_features', 4), ('min_samples_split', 6), ('min_samples_leaf', 4)]) 0.7496052016971919\n",
      "dict_items([('n_estimators', 130), ('max_depth', 15), ('max_features', 13), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.779383231966372\n",
      "dict_items([('n_estimators', 130), ('max_depth', 19), ('max_features', 4), ('min_samples_split', 7), ('min_samples_leaf', 3)]) 0.7785869409789805\n",
      "dict_items([('n_estimators', 130), ('max_depth', 15), ('max_features', 5), ('min_samples_split', 7), ('min_samples_leaf', 1)]) 0.7770575873389887\n",
      "dict_items([('n_estimators', 80), ('max_depth', 15), ('max_features', 14), ('min_samples_split', 3), ('min_samples_leaf', 1)]) 0.7799326037131348\n",
      "dict_items([('n_estimators', 180), ('max_depth', 23), ('max_features', 11), ('min_samples_split', 4), ('min_samples_leaf', 2)]) 0.7807318363822215\n",
      "dict_items([('n_estimators', 120), ('max_depth', 9), ('max_features', 3), ('min_samples_split', 4), ('min_samples_leaf', 1)]) 0.7470016037264212\n",
      "dict_items([('n_estimators', 170), ('max_depth', 17), ('max_features', 14), ('min_samples_split', 6), ('min_samples_leaf', 3)]) 0.7796199833015478\n",
      "dict_items([('n_estimators', 170), ('max_depth', 7), ('max_features', 5), ('min_samples_split', 5), ('min_samples_leaf', 1)]) 0.7454853521148901\n",
      "dict_items([('n_estimators', 130), ('max_depth', 19), ('max_features', 2), ('min_samples_split', 3), ('min_samples_leaf', 2)]) 0.773325016502496\n",
      "dict_items([('n_estimators', 150), ('max_depth', 17), ('max_features', 2), ('min_samples_split', 6), ('min_samples_leaf', 2)]) 0.77206043678031\n",
      "dict_items([('n_estimators', 180), ('max_depth', 5), ('max_features', 7), ('min_samples_split', 8), ('min_samples_leaf', 2)]) 0.7436212311006655\n"
     ]
    }
   ],
   "source": [
    "min_max_tuned = Rfc_h_tuning(data_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 43, 45, 5, 67, 34,5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([160, 21, 13, 5])\n"
     ]
    }
   ],
   "source": [
    "print(param_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('n_estimators', 160), ('max_depth', 21), ('max_features', 13), ('min_samples_split', 5)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
